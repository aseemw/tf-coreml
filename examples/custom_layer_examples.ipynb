{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the process of adding custom layers to the CoreML model during conversion. Three examples are discussed to cover different aspects of this process.\n",
    "\n",
    "CoreML supports a certain set of Neural Network layers. The list can be found [here](https://github.com/apple/coremltools/blob/master/mlmodel/format/NeuralNetwork.proto) or [here](https://apple.github.io/coremltools/coremlspecification/sections/NeuralNetwork.html).\n",
    "For TensorFlow operations (ops for short) that are not translatable to any of these CoreML layers, custom layers can be inserted in the CoreML model. At runtime, CoreML framework will look for the implementation code of the custom layer, which has to be provided by the developer in her app.   \n",
    "Custom layer is a [proto message](https://github.com/apple/coremltools/blob/5b5b8190764ffe78110be6b4d0edbeebe0253a6e/mlmodel/format/NeuralNetwork.proto#L2280), like any other neural netowrk layer in the .mlmodel file (which is in the protobuf format), that can hold the parameters and weights (if any) associated with the TF op.\n",
    "Here is more [documentation](https://developer.apple.com/documentation/coreml/core_ml_api/creating_a_custom_layer) on CoreML custom layers and a detailed [blogpost](http://machinethink.net/blog/coreml-custom-layers/). \n",
    "\n",
    "There are two ways in which a custom layer can be added during conversion:\n",
    "\n",
    "1. Specify the argument \"add_custom_layers=True\" during conversion and later edit the proto specification to add/remove any parameters. \n",
    "2. Specify the argument \"add_custom_layers=True\" and \"custom_conversion_functions\" to the converter. \n",
    "\n",
    "(for visualization we use netron)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aseem/Aseem_env/env/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:root:Keras version 2.1.5 detected. Last version known to be fully compatible of Keras is 2.1.3 .\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tempfile\n",
    "import os\n",
    "import tfcoreml\n",
    "import coremltools\n",
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "import netron # can remove this if you want to skip the visualization part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A utility function to freeze rhe graph. It will be used later\n",
    "def _simple_run_and_freeze(graph, output_name, frozen_model_file='', feed_dict={}):\n",
    "    \n",
    "    model_dir = tempfile.mkdtemp()\n",
    "    graph_def_file = os.path.join(model_dir, 'tf_graph.pbtxt')\n",
    "    checkpoint_file = os.path.join(model_dir, 'tf_model.ckpt')\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with graph.as_default() as g:\n",
    "      saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph = graph) as sess:\n",
    "      # initialize\n",
    "      sess.run(tf.global_variables_initializer())\n",
    "      # run the result\n",
    "      fetch = graph.get_operation_by_name(output_name).outputs[0]\n",
    "      tf_result = sess.run(fetch, feed_dict=feed_dict)\n",
    "      # save graph definition somewhere\n",
    "      tf.train.write_graph(sess.graph, model_dir, graph_def_file)\n",
    "      # save the weights\n",
    "      saver.save(sess, checkpoint_file)\n",
    "    \n",
    "    freeze_graph(input_graph=graph_def_file,\n",
    "                 input_saver=\"\",\n",
    "                 input_binary=False,\n",
    "                 input_checkpoint=checkpoint_file,\n",
    "                 output_node_names=output_name,\n",
    "                 restore_op_name=\"save/restore_all\",\n",
    "                 filename_tensor_name=\"save/Const:0\",\n",
    "                 output_graph=frozen_model_file,\n",
    "                 clear_devices=True,\n",
    "                 initializer_nodes=\"\")\n",
    "    \n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    \n",
    "    return tf_result\n",
    "\n",
    "# A utility function that takes an MLModel instance and prints info about Neural network layers inside it\n",
    "# It prints short info about all the NN layers and the full description info for the custom layer\n",
    "def _print_coreml_nn_layer_info(spec):\n",
    "    nn_layers = coremltools.models.utils._get_nn_layers(spec)\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        if layer.WhichOneof('layer') == 'custom':\n",
    "            print 'layer_id = ', i\n",
    "            print layer\n",
    "        else:\n",
    "            print('{}: layer type: ({}) , inputs: {}, outputs: {}'.\n",
    "              format(i,layer.WhichOneof('layer'), \", \".join([x for x in layer.input]), \", \".join([x for x in layer.output])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TF graph: input -> Dense -> unit norm -> output\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    inputs = tf.placeholder(tf.float32, shape=[None,8], name='input')\n",
    "    with slim.arg_scope([slim.fully_connected],\n",
    "          weights_initializer=tf.truncated_normal_initializer(0.0, 0.2),\n",
    "          weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        y = slim.fully_connected(inputs, 10, scope='fc')\n",
    "        y = slim.unit_norm(y,dim=1)\n",
    "\n",
    "output_name = y.op.name\n",
    "X = np.random.rand(1,8)\n",
    "frozen_model_file = 'unit_norm_graph.pb'\n",
    "coreml_model_path = 'unit_norm_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape, np.sum(out ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netron.serve_file(frozen_model_file, browse = True, port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['UnitNorm/div:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we get an unsupported op error. Try again with custom Flag set to true\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['UnitNorm/div:0'],\n",
    "        add_custom_layers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the \"Tile\" op was made into a custom layer in the CoreML model. This op takes in two inputs, it recasts the first one into the shape given by the second input (by repetition). Here is the [documentation](https://www.tensorflow.org/versions/master/api_docs/python/tf/tile).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize CoreML model\n",
    "netron.serve_file(coreml_model_path, browse = True, port=8081)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the visualization that the tensors, whose values do not change based on the graph inputs (potentially they depend on the shape of the input, which needs to be fixed during conversion) are converted to \"load constant\" layers in the CoreML graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inspect the CoreML model\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\"ClassName\" is an important message, as this is the name of the swift/objective-c class that needs to implemented in the Xcode app and will contain the actual code for running the layer.  \n",
    "The \"tile\" op does not have any parameters. Lets now convert a TF graph with an unsupported op that has parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a TF graph: input -> Dense -> softmax -> top_k -> output\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    x = tf.placeholder(tf.float32, shape=[None,8], name=\"input\")\n",
    "    y = tf.layers.dense(inputs=x, units=12, activation=tf.nn.relu)\n",
    "    y = tf.nn.softmax(y, axis=1)\n",
    "    y = tf.nn.top_k(y, k=3, sorted = False, name='output')\n",
    "    \n",
    "output_name = 'output'    \n",
    "X = np.random.rand(1,8)\n",
    "frozen_model_file = 'topk_graph.pb'\n",
    "coreml_model_path = 'topk_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netron.serve_file(frozen_model_file, browse = True, port=8082)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the CoreML model\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[top_k](https://www.tensorflow.org/api_docs/python/tf/nn/top_k) operation has two parameters: 'k' and 'sorted'. In the TF graph, the former is received as an additional input by the op and the latter is an op attribute. \n",
    "Let us modify the MLModel spec directly to add these two parameters to this layer. We need to know a little bit about the custom layer is a [proto message](https://github.com/apple/coremltools/blob/5b5b8190764ffe78110be6b4d0edbeebe0253a6e/mlmodel/format/NeuralNetwork.proto#L2280) to be able to do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_layers = coremltools.models.utils._get_nn_layers(spec)\n",
    "del nn_layers[3].input[1] # delete the second input: its just the value of k\n",
    "del nn_layers[3].output[1] # delete the second output\n",
    "nn_layers[3].custom.parameters[\"k\"].intValue = 3\n",
    "nn_layers[3].custom.parameters[\"sorted\"].boolValue = False\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the spec back out\n",
    "coremltools.models.utils.save_spec(spec, coreml_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize CoreML model\n",
    "netron.serve_file(coreml_model_path, browse = True, port=8083)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an alternate way to do the same thing using the \"custom_conversion_functions\" argument: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_topk(tf_op, optional_constant_inputs={}):\n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "    params.className = 'Top_K'\n",
    "    params.description = \"Custom layer that corresponds to the top_k TF op\"\n",
    "    params.parameters[\"sorted\"].boolValue = tf_op.get_attr('sorted')\n",
    "    # get the value of k\n",
    "    k = optional_constant_inputs.get(tf_op.inputs[1].name, 3)\n",
    "    params.parameters[\"k\"].intValue = k\n",
    "    return params, [tf_op.inputs[0].name], [tf_op.outputs[0].name]\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,8]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True,\n",
    "        custom_conversion_functions={'TopKV2': _convert_topk})\n",
    "\n",
    "print(\"\\n \\n ML Model layers info: \\n\")\n",
    "# inspect the CoreML model: this should be same as the one we got above\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Lets move on to the third and the final example. Now we will encounter an op that is supported but its configuration is not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpXXW_8X/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/09/hn9tml7d58nggsyxt54ymw5h0000gp/T/tmpXXW_8X/tf_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 1 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 1 variables to const ops.\n",
      "TF out:  output (1, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "# define a TF graph: input -> conv -> slice -> output\n",
    "tf.reset_default_graph()\n",
    "graph = tf.Graph()\n",
    "with graph.as_default() as g:\n",
    "    x = tf.placeholder(tf.float32, shape=[None,10,10,3], name=\"input\")\n",
    "    W = tf.Variable(tf.truncated_normal([1,1,3,5], stddev=0.1))\n",
    "    y = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    y = tf.slice(y, begin=[0,1,1,1], size=[1,2,2,2], name='output')\n",
    "    \n",
    "output_name = 'output'    \n",
    "X = np.random.rand(1,10,10,3)\n",
    "frozen_model_file = 'slice_graph.pb'\n",
    "coreml_model_path = 'slice_graph.mlmodel'\n",
    "out = _simple_run_and_freeze(graph, output_name, frozen_model_file, feed_dict={'input:0' : X})\n",
    "print 'TF out: ', output_name, out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netron.serve_file(frozen_model_file, browse = True, port=8084)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 2 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob input:0\n",
      "1/7: Analysing op name: output/size ( type:  Const )\n",
      "2/7: Analysing op name: output/begin ( type:  Const )\n",
      "3/7: Analysing op name: Variable ( type:  Const )\n",
      "4/7: Analysing op name: Variable/read ( type:  Identity )\n",
      "5/7: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "6/7: Analysing op name: Conv2D ( type:  Conv2D )\n",
      "7/7: Analysing op name: output ( type:  Slice )\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Slice case not handled (input shape: [1, 10, 10, 5], output shape: [1, 2, 2, 2])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-35c914f51c6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mmlmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoreml_model_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_name_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         output_feature_names=['output:0'])\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    548\u001b[0m       \u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m       \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_custom_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m       custom_conversion_functions=custom_conversion_functions)\n\u001b[0m",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_convert_pb_to_mlmodel\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    313\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_custom_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m   \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_conversion_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_conversion_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m   \u001b[0mconvert_ops_to_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m   \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_ops_to_layers.pyc\u001b[0m in \u001b[0;36mconvert_ops_to_layers\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtranslation_required\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mtranslator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m       \u001b[0mconnect_skipped_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aseem/Documents/code/tf-coreml-aseem/tf-coreml/tfcoreml/_layers.py\u001b[0m in \u001b[0;36mslice\u001b[0;34m(op, context)\u001b[0m\n\u001b[1;32m   1197\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m       \u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Slice case not handled (input shape: [1, 10, 10, 5], output shape: [1, 2, 2, 2])"
     ]
    }
   ],
   "source": [
    "# Try to convert it : this call should raise an error\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,10,10,3]},\n",
    "        output_feature_names=['output:0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This fails, so we provide a custom layer function. Note that this time, the key in the dictionary provided via  \"custom_conversion_functions\" should be same as the op name ('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 2 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob input:0\n",
      "1/7: Analysing op name: output/size ( type:  Const )\n",
      "2/7: Analysing op name: output/begin ( type:  Const )\n",
      "3/7: Analysing op name: Variable ( type:  Const )\n",
      "4/7: Analysing op name: Variable/read ( type:  Identity )\n",
      "5/7: Analysing op name: input ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "6/7: Analysing op name: Conv2D ( type:  Conv2D )\n",
      "7/7: Analysing op name: output ( type:  Slice )\n",
      "Adding custom layer\n",
      "\n",
      " Core ML model generated. Saved at location: slice_graph.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"input__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 3\n",
      "    shape: 10\n",
      "    shape: 10\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"output__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 2\n",
      "    shape: 2\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "\n",
      "\n",
      "Custom layers have been added to the CoreML model corresponding to the following ops in the TF graph: \n",
      "1/1: op type: Slice, op input names and shapes: [('Conv2D:0', [1, 10, 10, 5]), ('output/begin:0', [4]), ('output/size:0', [4])], op output names and shapes: [('output:0', [1, 2, 2, 2])]\n",
      "\n",
      " \n",
      " ML Model layers info: \n",
      "\n",
      "0: layer type: (convolution) , inputs: input__0, outputs: Conv2D:0\n",
      "layer_id =  1\n",
      "name: \"output\"\n",
      "input: \"Conv2D:0\"\n",
      "output: \"output__0\"\n",
      "custom {\n",
      "  className: \"Slice\"\n",
      "  weights {\n",
      "    floatValue: 0.0\n",
      "    floatValue: 1.0\n",
      "    floatValue: 1.0\n",
      "    floatValue: 1.0\n",
      "  }\n",
      "  weights {\n",
      "    floatValue: 1.0\n",
      "    floatValue: 2.0\n",
      "    floatValue: 2.0\n",
      "    floatValue: 2.0\n",
      "  }\n",
      "  description: \"Custom layer that corresponds to the slice TF op\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def _convert_slice(tf_op, optional_constant_inputs={}):\n",
    "    params = NeuralNetwork_pb2.CustomLayerParams()\n",
    "    params.className = 'Slice'\n",
    "    params.description = \"Custom layer that corresponds to the slice TF op\"\n",
    "    # get the value of begin\n",
    "    begin = optional_constant_inputs.get(tf_op.inputs[1].name, [0,0,0,0])\n",
    "    size = optional_constant_inputs.get(tf_op.inputs[2].name, [0,0,0,0])\n",
    "    # add begin and size as two repeated weight fields\n",
    "    begin_as_weights = params.weights.add()\n",
    "    begin_as_weights.floatValue.extend(map(float, begin))\n",
    "    size_as_weights = params.weights.add()\n",
    "    size_as_weights.floatValue.extend(map(float, size))\n",
    "    return params, [tf_op.inputs[0].name], [tf_op.outputs[0].name]\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file,\n",
    "        mlmodel_path=coreml_model_path,\n",
    "        input_name_shape_dict={'input:0':[1,10,10,3]},\n",
    "        output_feature_names=['output:0'],\n",
    "        add_custom_layers=True,\n",
    "        custom_conversion_functions={'output': _convert_slice}) # dictionary has op name as the key\n",
    "\n",
    "print(\"\\n \\n ML Model layers info: \\n\")\n",
    "# inspect the CoreML model: this should be same as the one we got above\n",
    "spec = coreml_model.get_spec()\n",
    "_print_coreml_nn_layer_info(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'slice_graph.mlmodel'\n",
      "Serving 'slice_graph.mlmodel' at http://localhost:8085\n",
      "\n",
      "Stopping\n"
     ]
    }
   ],
   "source": [
    "netron.serve_file(coreml_model_path, browse = True, port=8085)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
